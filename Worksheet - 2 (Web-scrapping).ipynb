{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23d5eefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Page\n",
      "Welcome to Wikipedia\n",
      "From today's featured article\n",
      "Did you know ...\n",
      "In the news\n",
      "On this day\n",
      "Today's featured picture\n",
      "Other areas of Wikipedia\n",
      "Wikipedia's sister projects\n",
      "Wikipedia languages\n",
      "Navigation menu\n",
      "\n",
      "Search\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Write a python program to display all the header tags from wikipedia.org.\n",
    "\n",
    "import  requests\n",
    "from  bs4 import BeautifulSoup\n",
    "\n",
    "url = requests.get('https://en.wikipedia.org/wiki/Main_Page')\n",
    "soup = BeautifulSoup(url.content)\n",
    "story = soup.find_all(['h1', 'h2','h3'])\n",
    "for i in story:\n",
    "    print(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55a5189b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titles</th>\n",
       "      <th>Year_of_Release</th>\n",
       "      <th>IMDB_Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n      1.\\n      The Shawshank Redemption\\n(1...</td>\n",
       "      <td>(1994)</td>\n",
       "      <td>\\n9.2\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n      2.\\n      The Godfather\\n(1972)\\n</td>\n",
       "      <td>(1972)</td>\n",
       "      <td>\\n9.2\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n      3.\\n      The Dark Knight\\n(2008)\\n</td>\n",
       "      <td>(2008)</td>\n",
       "      <td>\\n9.0\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n      4.\\n      The Godfather: Part II\\n(197...</td>\n",
       "      <td>(1974)</td>\n",
       "      <td>\\n9.0\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n      5.\\n      12 Angry Men\\n(1957)\\n</td>\n",
       "      <td>(1957)</td>\n",
       "      <td>\\n8.9\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>\\n      96.\\n      Jagten\\n(2012)\\n</td>\n",
       "      <td>(2012)</td>\n",
       "      <td>\\n8.3\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>\\n      97.\\n      Everything Everywhere All a...</td>\n",
       "      <td>(2022)</td>\n",
       "      <td>\\n8.3\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>\\n      98.\\n      M - Eine Stadt sucht einen ...</td>\n",
       "      <td>(1931)</td>\n",
       "      <td>\\n8.3\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>\\n      99.\\n      North by Northwest\\n(1959)\\n</td>\n",
       "      <td>(1959)</td>\n",
       "      <td>\\n8.3\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>\\n      100.\\n      Vertigo\\n(1958)\\n</td>\n",
       "      <td>(1958)</td>\n",
       "      <td>\\n8.2\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Titles Year_of_Release  \\\n",
       "0   \\n      1.\\n      The Shawshank Redemption\\n(1...          (1994)   \n",
       "1           \\n      2.\\n      The Godfather\\n(1972)\\n          (1972)   \n",
       "2         \\n      3.\\n      The Dark Knight\\n(2008)\\n          (2008)   \n",
       "3   \\n      4.\\n      The Godfather: Part II\\n(197...          (1974)   \n",
       "4            \\n      5.\\n      12 Angry Men\\n(1957)\\n          (1957)   \n",
       "..                                                ...             ...   \n",
       "95                \\n      96.\\n      Jagten\\n(2012)\\n          (2012)   \n",
       "96  \\n      97.\\n      Everything Everywhere All a...          (2022)   \n",
       "97  \\n      98.\\n      M - Eine Stadt sucht einen ...          (1931)   \n",
       "98    \\n      99.\\n      North by Northwest\\n(1959)\\n          (1959)   \n",
       "99              \\n      100.\\n      Vertigo\\n(1958)\\n          (1958)   \n",
       "\n",
       "   IMDB_Ratings  \n",
       "0       \\n9.2\\n  \n",
       "1       \\n9.2\\n  \n",
       "2       \\n9.0\\n  \n",
       "3       \\n9.0\\n  \n",
       "4       \\n8.9\\n  \n",
       "..          ...  \n",
       "95      \\n8.3\\n  \n",
       "96      \\n8.3\\n  \n",
       "97      \\n8.3\\n  \n",
       "98      \\n8.3\\n  \n",
       "99      \\n8.2\\n  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A python program to display IMDB’s Top rated 100 movies’ data(i.e. name, rating, year of release)\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "page = requests.get('https://www.imdb.com/chart/top')\n",
    "soup = BeautifulSoup(page.content)\n",
    "first_title = soup.find('td',class_='titleColumn')\n",
    "first_title.text\n",
    "year = soup.find('span',class_='secondaryInfo')\n",
    "year.text\n",
    "ratings = soup.find('td',class_='ratingColumn imdbRating')\n",
    "ratings.text\n",
    "\n",
    "title = []\n",
    "for i in soup.find_all('td',class_='titleColumn'):title.append(i.text)\n",
    "title\n",
    "\n",
    "year = []\n",
    "for i in soup.find_all('span',class_='secondaryInfo'):year.append(i.text)\n",
    "year\n",
    "\n",
    "ratings = []\n",
    "for i in soup.find_all('td',class_='ratingColumn imdbRating'):ratings.append(i.text)\n",
    "ratings\n",
    "\n",
    "#Making DataFrame\n",
    "df = pd.DataFrame({'Titles':title,'Year_of_Release':year,'IMDB_Ratings':ratings})\n",
    "df\n",
    "\n",
    "# respective index position\n",
    "update_df = df.drop(df.index[100:],)\n",
    " \n",
    "update_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2592b819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titles</th>\n",
       "      <th>Year_of_Release</th>\n",
       "      <th>IMDB_Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n      1.\\n      Jai Bhim\\n(2021)\\n</td>\n",
       "      <td>(2021)</td>\n",
       "      <td>\\n8.4\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n      2.\\n      Anbe Sivam\\n(2003)\\n</td>\n",
       "      <td>(2003)</td>\n",
       "      <td>\\n8.4\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n      3.\\n      Golmaal\\n(1979)\\n</td>\n",
       "      <td>(1979)</td>\n",
       "      <td>\\n8.4\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n      4.\\n      Nayakan\\n(1987)\\n</td>\n",
       "      <td>(1987)</td>\n",
       "      <td>\\n8.4\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n      5.\\n      Pariyerum Perumal\\n(2018)\\n</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>\\n8.4\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>\\n      96.\\n      Masaan\\n(2015)\\n</td>\n",
       "      <td>(2015)</td>\n",
       "      <td>\\n8.0\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>\\n      97.\\n      Dil Chahta Hai\\n(2001)\\n</td>\n",
       "      <td>(2001)</td>\n",
       "      <td>\\n8.0\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>\\n      98.\\n      Kahaani\\n(2012)\\n</td>\n",
       "      <td>(2012)</td>\n",
       "      <td>\\n8.0\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>\\n      99.\\n      Maheshinte Prathikaaram\\n(2...</td>\n",
       "      <td>(2016)</td>\n",
       "      <td>\\n8.0\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>\\n      100.\\n      Baahubali 2: The Conclusio...</td>\n",
       "      <td>(2017)</td>\n",
       "      <td>\\n8.0\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Titles Year_of_Release  \\\n",
       "0                \\n      1.\\n      Jai Bhim\\n(2021)\\n          (2021)   \n",
       "1              \\n      2.\\n      Anbe Sivam\\n(2003)\\n          (2003)   \n",
       "2                 \\n      3.\\n      Golmaal\\n(1979)\\n          (1979)   \n",
       "3                 \\n      4.\\n      Nayakan\\n(1987)\\n          (1987)   \n",
       "4       \\n      5.\\n      Pariyerum Perumal\\n(2018)\\n          (2018)   \n",
       "..                                                ...             ...   \n",
       "95                \\n      96.\\n      Masaan\\n(2015)\\n          (2015)   \n",
       "96        \\n      97.\\n      Dil Chahta Hai\\n(2001)\\n          (2001)   \n",
       "97               \\n      98.\\n      Kahaani\\n(2012)\\n          (2012)   \n",
       "98  \\n      99.\\n      Maheshinte Prathikaaram\\n(2...          (2016)   \n",
       "99  \\n      100.\\n      Baahubali 2: The Conclusio...          (2017)   \n",
       "\n",
       "   IMDB_Ratings  \n",
       "0       \\n8.4\\n  \n",
       "1       \\n8.4\\n  \n",
       "2       \\n8.4\\n  \n",
       "3       \\n8.4\\n  \n",
       "4       \\n8.4\\n  \n",
       "..          ...  \n",
       "95      \\n8.0\\n  \n",
       "96      \\n8.0\\n  \n",
       "97      \\n8.0\\n  \n",
       "98      \\n8.0\\n  \n",
       "99      \\n8.0\\n  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A python program to display IMDB’s Top rated 100 Indian movies’ data(i.e. name, rating, year of release)\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "page = requests.get('https://www.imdb.com/india/top-rated-indian-movies')\n",
    "soup = BeautifulSoup(page.content)\n",
    "first_title = soup.find('td',class_='titleColumn')\n",
    "first_title.text\n",
    "year = soup.find('span',class_='secondaryInfo')\n",
    "year.text\n",
    "ratings = soup.find('td',class_='ratingColumn imdbRating')\n",
    "ratings.text\n",
    "\n",
    "title = []\n",
    "for i in soup.find_all('td',class_='titleColumn'):title.append(i.text)\n",
    "title\n",
    "\n",
    "year = []\n",
    "for i in soup.find_all('span',class_='secondaryInfo'):year.append(i.text)\n",
    "year\n",
    "\n",
    "ratings = []\n",
    "for i in soup.find_all('td',class_='ratingColumn imdbRating'):ratings.append(i.text)\n",
    "ratings\n",
    "\n",
    "#Making DataFrame\n",
    "df = pd.DataFrame({'Titles':title,'Year_of_Release':year,'IMDB_Ratings':ratings})\n",
    "df\n",
    "\n",
    "# respective index position\n",
    "update_df = df.drop(df.index[100:],)\n",
    " \n",
    "update_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9787dcdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Former Presidents</th>\n",
       "      <th>Term of Office</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nShri Pranab Mukherjee (1935-2020)\\nTerm of O...</td>\n",
       "      <td>Term of Office:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nSmt Pratibha Devisingh Patil (birth - 1934)\\...</td>\n",
       "      <td>Term of Office:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nDR. A.P.J. Abdul Kalam (1931-2015)\\nTerm of ...</td>\n",
       "      <td>Term of Office:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nShri K. R. Narayanan (1920 - 2005)\\nTerm of ...</td>\n",
       "      <td>Term of Office:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nDr Shankar Dayal Sharma (1918-1999)\\nTerm of...</td>\n",
       "      <td>Term of Office:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\\nShri R Venkataraman (1910-2009)\\nTerm of Off...</td>\n",
       "      <td>Term of Office:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\\nGiani Zail Singh (1916-1994)\\nTerm of Office...</td>\n",
       "      <td>Term of Office:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\\nShri Neelam Sanjiva Reddy (1913-1996)\\nTerm ...</td>\n",
       "      <td>Term of Office:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\\nDr. Fakhruddin Ali Ahmed (1905-1977)\\nTerm o...</td>\n",
       "      <td>Term of Office:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\\nShri Varahagiri Venkata Giri (1894-1980)\\nTe...</td>\n",
       "      <td>Term of Office:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\\nDr. Zakir Husain (1897-1969)\\nTerm of Office...</td>\n",
       "      <td>Term of Office:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>\\nDr. Sarvepalli Radhakrishnan (1888-1975)\\nTe...</td>\n",
       "      <td>Term of Office:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\\nDr. Rajendra Prasad (1884-1963) \\nTerm of Of...</td>\n",
       "      <td>Term of Office:</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Former Presidents   Term of Office\n",
       "0   \\nShri Pranab Mukherjee (1935-2020)\\nTerm of O...  Term of Office:\n",
       "1   \\nSmt Pratibha Devisingh Patil (birth - 1934)\\...  Term of Office:\n",
       "2   \\nDR. A.P.J. Abdul Kalam (1931-2015)\\nTerm of ...  Term of Office:\n",
       "3   \\nShri K. R. Narayanan (1920 - 2005)\\nTerm of ...  Term of Office:\n",
       "4   \\nDr Shankar Dayal Sharma (1918-1999)\\nTerm of...  Term of Office:\n",
       "5   \\nShri R Venkataraman (1910-2009)\\nTerm of Off...  Term of Office:\n",
       "6   \\nGiani Zail Singh (1916-1994)\\nTerm of Office...  Term of Office:\n",
       "7   \\nShri Neelam Sanjiva Reddy (1913-1996)\\nTerm ...  Term of Office:\n",
       "8   \\nDr. Fakhruddin Ali Ahmed (1905-1977)\\nTerm o...  Term of Office:\n",
       "9   \\nShri Varahagiri Venkata Giri (1894-1980)\\nTe...  Term of Office:\n",
       "10  \\nDr. Zakir Husain (1897-1969)\\nTerm of Office...  Term of Office:\n",
       "11  \\nDr. Sarvepalli Radhakrishnan (1888-1975)\\nTe...  Term of Office:\n",
       "12  \\nDr. Rajendra Prasad (1884-1963) \\nTerm of Of...  Term of Office:"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A python program to display list of respected former presidents of India(i.e. Name , Term of office)\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "page = requests.get('https://presidentofindia.nic.in/former-presidents.htm')\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "first_name = soup.find('div',class_='presidentListing')\n",
    "first_name.text\n",
    "term = soup.find('span',class_='terms')\n",
    "term.text\n",
    "\n",
    "name = []\n",
    "for i in soup.find_all('div',class_='presidentListing'):name.append(i.text)\n",
    "name\n",
    "\n",
    "term = []\n",
    "for i in soup.find_all('span',class_='terms'):term.append(i.text)\n",
    "term\n",
    "\n",
    "#Making DataFrame\n",
    "df = pd.DataFrame({'Former Presidents':name,'Term of Office':term})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7e6f2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50426b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Articles</th>\n",
       "      <th>Time</th>\n",
       "      <th>Links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Etsy has 54% upside as it becomes a \"top-of-mi...</td>\n",
       "      <td>10 Min Ago</td>\n",
       "      <td>/pro/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>India is better positioned to weather food inf...</td>\n",
       "      <td>42 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/01/india-is-bette...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oil group OPEC+ reportedly considering suspend...</td>\n",
       "      <td>1 Hour Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/01/oil-group-opec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Treasury yields rise at start of June, with in...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/01/us-bonds-treas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Russian bombing of chemical plant ‘insanity’; ...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/01/russia-ukraine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rimac raised 500 million euros to expand EV pa...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/01/croatian-ev-su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>European stocks make mixed start to June as in...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/01/europe-markets...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chinese electric car start-up WM Motor files t...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/01/chinese-electr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Crypto deals help fuel NBA sponsorships to $1....</td>\n",
       "      <td>6 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/01/crypto-deals-h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Wall Street veterans offer 3 trading strategie...</td>\n",
       "      <td>6 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/01/trading-strate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Worried about the sell-off? It's time to mix i...</td>\n",
       "      <td>7 Hours Ago</td>\n",
       "      <td>/pro/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>India sees a second chance to pivot to the Ind...</td>\n",
       "      <td>8 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/01/india-sees-a-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Autoworker union accuses GM joint venture of d...</td>\n",
       "      <td>9 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/31/autoworker-uni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Cramer's lightning round: Century Aluminum is ...</td>\n",
       "      <td>10 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/31/cramers-lightn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Asia stocks mixed as private survey shows Chin...</td>\n",
       "      <td>10 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/06/01/asia-markets-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Salesforce reports strong demand in an uncerta...</td>\n",
       "      <td>11 Hours Ago</td>\n",
       "      <td>/investingclub/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Charts suggest 'it's going to be a very nice s...</td>\n",
       "      <td>11 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/31/jim-cramer-cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Benioff says foreign exchange pushed Salesforc...</td>\n",
       "      <td>11 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/31/benioff-foreig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Jim Cramer says these three Big Tech stocks ha...</td>\n",
       "      <td>12 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/31/cramer-these-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Stock futures rise ahead of first day of June</td>\n",
       "      <td>12 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/31/stock-market-n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Best trades on CNBC Tuesday: Pros are buying t...</td>\n",
       "      <td>12 Hours Ago</td>\n",
       "      <td>/pro/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>These charts show how Russia's invasion of Ukr...</td>\n",
       "      <td>13 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/31/these-charts-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Supreme Court blocks Texas social media law op...</td>\n",
       "      <td>13 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/31/supreme-court-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Stocks making the biggest moves after hours: S...</td>\n",
       "      <td>13 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/31/stocks-moving-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Facebook's transformation to Meta will be comp...</td>\n",
       "      <td>13 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/31/meta-will-chan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>BTS draws massive crowd to White House press b...</td>\n",
       "      <td>13 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/31/bts-meets-with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Victoria's Secret beats profit forecast, warns...</td>\n",
       "      <td>13 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/31/victorias-secr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Salesforce stock jumps on higher profit foreca...</td>\n",
       "      <td>14 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/05/31/salesforce-crm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>These buy-rated stocks are expected to generat...</td>\n",
       "      <td>14 Hours Ago</td>\n",
       "      <td>/pro/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Why our energy stocks could still go higher fr...</td>\n",
       "      <td>15 Hours Ago</td>\n",
       "      <td>/investingclub/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Articles          Time  \\\n",
       "0   Etsy has 54% upside as it becomes a \"top-of-mi...    10 Min Ago   \n",
       "1   India is better positioned to weather food inf...    42 Min Ago   \n",
       "2   Oil group OPEC+ reportedly considering suspend...    1 Hour Ago   \n",
       "3   Treasury yields rise at start of June, with in...   2 Hours Ago   \n",
       "4   Russian bombing of chemical plant ‘insanity’; ...   2 Hours Ago   \n",
       "5   Rimac raised 500 million euros to expand EV pa...   4 Hours Ago   \n",
       "6   European stocks make mixed start to June as in...   4 Hours Ago   \n",
       "7   Chinese electric car start-up WM Motor files t...   5 Hours Ago   \n",
       "8   Crypto deals help fuel NBA sponsorships to $1....   6 Hours Ago   \n",
       "9   Wall Street veterans offer 3 trading strategie...   6 Hours Ago   \n",
       "10  Worried about the sell-off? It's time to mix i...   7 Hours Ago   \n",
       "11  India sees a second chance to pivot to the Ind...   8 Hours Ago   \n",
       "12  Autoworker union accuses GM joint venture of d...   9 Hours Ago   \n",
       "13  Cramer's lightning round: Century Aluminum is ...  10 Hours Ago   \n",
       "14  Asia stocks mixed as private survey shows Chin...  10 Hours Ago   \n",
       "15  Salesforce reports strong demand in an uncerta...  11 Hours Ago   \n",
       "16  Charts suggest 'it's going to be a very nice s...  11 Hours Ago   \n",
       "17  Benioff says foreign exchange pushed Salesforc...  11 Hours Ago   \n",
       "18  Jim Cramer says these three Big Tech stocks ha...  12 Hours Ago   \n",
       "19      Stock futures rise ahead of first day of June  12 Hours Ago   \n",
       "20  Best trades on CNBC Tuesday: Pros are buying t...  12 Hours Ago   \n",
       "21  These charts show how Russia's invasion of Ukr...  13 Hours Ago   \n",
       "22  Supreme Court blocks Texas social media law op...  13 Hours Ago   \n",
       "23  Stocks making the biggest moves after hours: S...  13 Hours Ago   \n",
       "24  Facebook's transformation to Meta will be comp...  13 Hours Ago   \n",
       "25  BTS draws massive crowd to White House press b...  13 Hours Ago   \n",
       "26  Victoria's Secret beats profit forecast, warns...  13 Hours Ago   \n",
       "27  Salesforce stock jumps on higher profit foreca...  14 Hours Ago   \n",
       "28  These buy-rated stocks are expected to generat...  14 Hours Ago   \n",
       "29  Why our energy stocks could still go higher fr...  15 Hours Ago   \n",
       "\n",
       "                                                Links  \n",
       "0                                               /pro/  \n",
       "1   https://www.cnbc.com/2022/06/01/india-is-bette...  \n",
       "2   https://www.cnbc.com/2022/06/01/oil-group-opec...  \n",
       "3   https://www.cnbc.com/2022/06/01/us-bonds-treas...  \n",
       "4   https://www.cnbc.com/2022/06/01/russia-ukraine...  \n",
       "5   https://www.cnbc.com/2022/06/01/croatian-ev-su...  \n",
       "6   https://www.cnbc.com/2022/06/01/europe-markets...  \n",
       "7   https://www.cnbc.com/2022/06/01/chinese-electr...  \n",
       "8   https://www.cnbc.com/2022/06/01/crypto-deals-h...  \n",
       "9   https://www.cnbc.com/2022/06/01/trading-strate...  \n",
       "10                                              /pro/  \n",
       "11  https://www.cnbc.com/2022/06/01/india-sees-a-s...  \n",
       "12  https://www.cnbc.com/2022/05/31/autoworker-uni...  \n",
       "13  https://www.cnbc.com/2022/05/31/cramers-lightn...  \n",
       "14  https://www.cnbc.com/2022/06/01/asia-markets-c...  \n",
       "15                                    /investingclub/  \n",
       "16  https://www.cnbc.com/2022/05/31/jim-cramer-cha...  \n",
       "17  https://www.cnbc.com/2022/05/31/benioff-foreig...  \n",
       "18  https://www.cnbc.com/2022/05/31/cramer-these-t...  \n",
       "19  https://www.cnbc.com/2022/05/31/stock-market-n...  \n",
       "20                                              /pro/  \n",
       "21  https://www.cnbc.com/2022/05/31/these-charts-s...  \n",
       "22  https://www.cnbc.com/2022/05/31/supreme-court-...  \n",
       "23  https://www.cnbc.com/2022/05/31/stocks-moving-...  \n",
       "24  https://www.cnbc.com/2022/05/31/meta-will-chan...  \n",
       "25  https://www.cnbc.com/2022/05/31/bts-meets-with...  \n",
       "26  https://www.cnbc.com/2022/05/31/victorias-secr...  \n",
       "27  https://www.cnbc.com/2022/05/31/salesforce-crm...  \n",
       "28                                              /pro/  \n",
       "29                                    /investingclub/  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A python program to scrape mentioned news details from (https://www.cnbc.com/world/?region=world)\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "page = requests.get('https://www.cnbc.com/world/?region=world')\n",
    "page\n",
    "soup = BeautifulSoup(page.content)\n",
    "soup\n",
    "\n",
    "headlines = []\n",
    "for i in soup.find_all('a',class_='LatestNews-headline'):headlines.append(i.text)\n",
    "headlines\n",
    "\n",
    "time = []\n",
    "for i in soup.find_all('span',class_='LatestNews-wrapper'):time.append(i.text)\n",
    "time\n",
    "\n",
    "links = []\n",
    "for i in soup.find_all('li',class_='LatestNews-item'):links.append(i.a['href'])\n",
    "links\n",
    "\n",
    "df = pd.DataFrame({'Articles':headlines,'Time':time,'Links':links})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1e66e6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurents_Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Image_URL</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Castle BarbequeConnaught Place, Central Delhi</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>₹ 2,000 for 2 (approx) | North Indian, Chinese</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jungle Jamboree3CS Mall,Lajpat Nagar - 3, Sout...</td>\n",
       "      <td>3CS Mall,Lajpat Nagar - 3, South Delhi</td>\n",
       "      <td>₹ 1,400 for 2 (approx) | North Indian, Asian, ...</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Castle BarbequePacific Mall,Tagore Garden, Wes...</td>\n",
       "      <td>Pacific Mall,Tagore Garden, West Delhi</td>\n",
       "      <td>₹ 2,000 for 2 (approx) | Chinese, North Indian</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cafe KnoshThe Leela Ambience Convention Hotel,...</td>\n",
       "      <td>The Leela Ambience Convention Hotel,Shahdara, ...</td>\n",
       "      <td>₹ 3,000 for 2 (approx) | Italian, Continental</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Barbeque CompanyGardens Galleria,Sector 38...</td>\n",
       "      <td>Gardens Galleria,Sector 38A, Noida</td>\n",
       "      <td>₹ 1,700 for 2 (approx) | North Indian, Chinese...</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>India GrillHilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>Hilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>₹ 2,400 for 2 (approx) | North Indian, Italian</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Delhi BarbequeTaurus Sarovar Portico,Mahipalpu...</td>\n",
       "      <td>Taurus Sarovar Portico,Mahipalpur, South Delhi</td>\n",
       "      <td>₹ 1,800 for 2 (approx) | North Indian</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Monarch - Bar Be Que VillageIndirapuram Ha...</td>\n",
       "      <td>Indirapuram Habitat Centre,Indirapuram, Ghaziabad</td>\n",
       "      <td>₹ 1,900 for 2 (approx) | North Indian</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>World CafeVibe by The Lalit Traveller,Sector 3...</td>\n",
       "      <td>Vibe by The Lalit Traveller,Sector 35, Faridabad</td>\n",
       "      <td>₹ 2,400 for 2 (approx) | North Indian, Italian</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Indian Grill RoomSuncity Business Tower,Golf C...</td>\n",
       "      <td>Suncity Business Tower,Golf Course Road, Gurgaon</td>\n",
       "      <td>₹ 2,200 for 2 (approx) | North Indian, Mughlai</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mad 4 Bar B QueSector 29, Faridabad</td>\n",
       "      <td>Sector 29, Faridabad</td>\n",
       "      <td>₹ 800 for 2 (approx) | North Indian</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Barbeque 29NIT, Faridabad</td>\n",
       "      <td>NIT, Faridabad</td>\n",
       "      <td>₹ 1,500 for 2 (approx) | North Indian, Mughlai...</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GlasshouseDoubleTree By Hilton Gurugram Baani ...</td>\n",
       "      <td>DoubleTree By Hilton Gurugram Baani Square,Sec...</td>\n",
       "      <td>₹ 3,400 for 2 (approx) | European, Italian, As...</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Restaurents_Name  \\\n",
       "0       Castle BarbequeConnaught Place, Central Delhi   \n",
       "1   Jungle Jamboree3CS Mall,Lajpat Nagar - 3, Sout...   \n",
       "2   Castle BarbequePacific Mall,Tagore Garden, Wes...   \n",
       "3   Cafe KnoshThe Leela Ambience Convention Hotel,...   \n",
       "4   The Barbeque CompanyGardens Galleria,Sector 38...   \n",
       "5     India GrillHilton Garden Inn,Saket, South Delhi   \n",
       "6   Delhi BarbequeTaurus Sarovar Portico,Mahipalpu...   \n",
       "7   The Monarch - Bar Be Que VillageIndirapuram Ha...   \n",
       "8   World CafeVibe by The Lalit Traveller,Sector 3...   \n",
       "9   Indian Grill RoomSuncity Business Tower,Golf C...   \n",
       "10                Mad 4 Bar B QueSector 29, Faridabad   \n",
       "11                          Barbeque 29NIT, Faridabad   \n",
       "12  GlasshouseDoubleTree By Hilton Gurugram Baani ...   \n",
       "\n",
       "                                             Location  \\\n",
       "0                      Connaught Place, Central Delhi   \n",
       "1              3CS Mall,Lajpat Nagar - 3, South Delhi   \n",
       "2              Pacific Mall,Tagore Garden, West Delhi   \n",
       "3   The Leela Ambience Convention Hotel,Shahdara, ...   \n",
       "4                  Gardens Galleria,Sector 38A, Noida   \n",
       "5                Hilton Garden Inn,Saket, South Delhi   \n",
       "6      Taurus Sarovar Portico,Mahipalpur, South Delhi   \n",
       "7   Indirapuram Habitat Centre,Indirapuram, Ghaziabad   \n",
       "8    Vibe by The Lalit Traveller,Sector 35, Faridabad   \n",
       "9    Suncity Business Tower,Golf Course Road, Gurgaon   \n",
       "10                               Sector 29, Faridabad   \n",
       "11                                     NIT, Faridabad   \n",
       "12  DoubleTree By Hilton Gurugram Baani Square,Sec...   \n",
       "\n",
       "                                              Cuisine  \\\n",
       "0      ₹ 2,000 for 2 (approx) | North Indian, Chinese   \n",
       "1   ₹ 1,400 for 2 (approx) | North Indian, Asian, ...   \n",
       "2      ₹ 2,000 for 2 (approx) | Chinese, North Indian   \n",
       "3       ₹ 3,000 for 2 (approx) | Italian, Continental   \n",
       "4   ₹ 1,700 for 2 (approx) | North Indian, Chinese...   \n",
       "5      ₹ 2,400 for 2 (approx) | North Indian, Italian   \n",
       "6               ₹ 1,800 for 2 (approx) | North Indian   \n",
       "7               ₹ 1,900 for 2 (approx) | North Indian   \n",
       "8      ₹ 2,400 for 2 (approx) | North Indian, Italian   \n",
       "9      ₹ 2,200 for 2 (approx) | North Indian, Mughlai   \n",
       "10                ₹ 800 for 2 (approx) | North Indian   \n",
       "11  ₹ 1,500 for 2 (approx) | North Indian, Mughlai...   \n",
       "12  ₹ 3,400 for 2 (approx) | European, Italian, As...   \n",
       "\n",
       "                                            Image_URL Ratings  \n",
       "0   https://im1.dineout.co.in/images/uploads/resta...     3.5  \n",
       "1   https://im1.dineout.co.in/images/uploads/resta...     3.9  \n",
       "2   https://im1.dineout.co.in/images/uploads/resta...     3.9  \n",
       "3   https://im1.dineout.co.in/images/uploads/resta...     4.3  \n",
       "4   https://im1.dineout.co.in/images/uploads/resta...       4  \n",
       "5   https://im1.dineout.co.in/images/uploads/resta...     3.9  \n",
       "6   https://im1.dineout.co.in/images/uploads/resta...     3.7  \n",
       "7   https://im1.dineout.co.in/images/uploads/resta...     3.8  \n",
       "8   https://im1.dineout.co.in/images/uploads/resta...     4.2  \n",
       "9   https://im1.dineout.co.in/images/uploads/resta...     4.3  \n",
       "10  https://im1.dineout.co.in/images/uploads/resta...     3.6  \n",
       "11  https://im1.dineout.co.in/images/uploads/resta...     4.2  \n",
       "12  https://im1.dineout.co.in/images/uploads/resta...       4  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A python program to scrape mentioned details from dineout.co.in(Restaurant name,Cuisine,Location,Ratings,Image URL)\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "page = requests.get('https://www.dineout.co.in/delhi-restaurants/buffet-special')\n",
    "page\n",
    "soup = BeautifulSoup(page.content)\n",
    "soup\n",
    "titles = []\n",
    "for i in soup.find_all('div',class_='restnt-info cursor'):titles.append(i.text)\n",
    "titles\n",
    "loc = []\n",
    "for i in soup.find_all('div',class_='restnt-loc ellipsis'):loc.append(i.text)\n",
    "loc\n",
    "cuisine = []\n",
    "for i in soup.find_all('div',class_='detail-info'):cuisine.append(i.text)\n",
    "cuisine\n",
    "image = []\n",
    "for i in soup.find_all('img',class_='no-img'):image.append(i['data-src'])\n",
    "image\n",
    "rating = []\n",
    "for i in soup.find_all('div',class_='restnt-rating rating-4'):rating.append(i.text)\n",
    "rating\n",
    "\n",
    "df = pd.DataFrame({'Restaurents_Name':titles,'Location':loc,'Cuisine':cuisine,'Image_URL':image,'Ratings':rating})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f85a09a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper_Titles</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Published_Date</th>\n",
       "      <th>Paper_URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reward is enoughSilver, David, Singh, Satinder...</td>\n",
       "      <td>Silver, David, Singh, Satinder, Precup, Doina,...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Making sense of raw inputEvans, Richard, Bošnj...</td>\n",
       "      <td>Evans, Richard, Bošnjak, Matko and 5 more</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Law and logic: A review from an argumentation ...</td>\n",
       "      <td>Prakken, Henry, Sartor, Giovanni</td>\n",
       "      <td>October 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Creativity and artificial intelligenceBoden, M...</td>\n",
       "      <td>Boden, Margaret A.</td>\n",
       "      <td>August 1998</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Artificial cognition for social human–robot in...</td>\n",
       "      <td>Lemaignan, Séverin, Warnier, Mathieu and 3 more</td>\n",
       "      <td>June 2017</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Explanation in artificial intelligence: Insigh...</td>\n",
       "      <td>Miller, Tim</td>\n",
       "      <td>February 2019</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Making sense of sensory inputEvans, Richard, H...</td>\n",
       "      <td>Evans, Richard, Hernández-Orallo, José and 3 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Conflict-based search for optimal multi-agent ...</td>\n",
       "      <td>Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...</td>\n",
       "      <td>February 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Between MDPs and semi-MDPs: A framework for te...</td>\n",
       "      <td>Sutton, Richard S., Precup, Doina, Singh, Sati...</td>\n",
       "      <td>August 1999</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Hanabi challenge: A new frontier for AI re...</td>\n",
       "      <td>Bard, Nolan, Foerster, Jakob N. and 13 more</td>\n",
       "      <td>March 2020</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Evaluating XAI: A comparison of rule-based and...</td>\n",
       "      <td>van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...</td>\n",
       "      <td>February 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Argumentation in artificial intelligenceBench-...</td>\n",
       "      <td>Bench-Capon, T.J.M., Dunne, Paul E.</td>\n",
       "      <td>October 2007</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Algorithms for computing strategies in two-pla...</td>\n",
       "      <td>Bošanský, Branislav, Lisý, Viliam and 3 more</td>\n",
       "      <td>August 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Multiple object tracking: A literature reviewL...</td>\n",
       "      <td>Luo, Wenhan, Xing, Junliang and 4 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Selection of relevant features and examples in...</td>\n",
       "      <td>Blum, Avrim L., Langley, Pat</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A survey of inverse reinforcement learning: Ch...</td>\n",
       "      <td>Arora, Saurabh, Doshi, Prashant</td>\n",
       "      <td>August 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Explaining individual predictions when feature...</td>\n",
       "      <td>Aas, Kjersti, Jullum, Martin, Løland, Anders</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A review of possible effects of cognitive bias...</td>\n",
       "      <td>Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...</td>\n",
       "      <td>June 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Integrating social power into the decision-mak...</td>\n",
       "      <td>Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.</td>\n",
       "      <td>December 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>“That's (not) the output I expected!” On the r...</td>\n",
       "      <td>Riveiro, Maria, Thill, Serge</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Explaining black-box classifiers using post-ho...</td>\n",
       "      <td>Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...</td>\n",
       "      <td>May 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Algorithm runtime prediction: Methods &amp; evalua...</td>\n",
       "      <td>Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...</td>\n",
       "      <td>January 2014</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Wrappers for feature subset selectionKohavi, R...</td>\n",
       "      <td>Kohavi, Ron, John, George H.</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Commonsense visual sensemaking for autonomous ...</td>\n",
       "      <td>Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Quantum computation, quantum theory and AIYing...</td>\n",
       "      <td>Ying, Mingsheng</td>\n",
       "      <td>February 2010</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Paper_Titles  \\\n",
       "0   Reward is enoughSilver, David, Singh, Satinder...   \n",
       "1   Making sense of raw inputEvans, Richard, Bošnj...   \n",
       "2   Law and logic: A review from an argumentation ...   \n",
       "3   Creativity and artificial intelligenceBoden, M...   \n",
       "4   Artificial cognition for social human–robot in...   \n",
       "5   Explanation in artificial intelligence: Insigh...   \n",
       "6   Making sense of sensory inputEvans, Richard, H...   \n",
       "7   Conflict-based search for optimal multi-agent ...   \n",
       "8   Between MDPs and semi-MDPs: A framework for te...   \n",
       "9   The Hanabi challenge: A new frontier for AI re...   \n",
       "10  Evaluating XAI: A comparison of rule-based and...   \n",
       "11  Argumentation in artificial intelligenceBench-...   \n",
       "12  Algorithms for computing strategies in two-pla...   \n",
       "13  Multiple object tracking: A literature reviewL...   \n",
       "14  Selection of relevant features and examples in...   \n",
       "15  A survey of inverse reinforcement learning: Ch...   \n",
       "16  Explaining individual predictions when feature...   \n",
       "17  A review of possible effects of cognitive bias...   \n",
       "18  Integrating social power into the decision-mak...   \n",
       "19  “That's (not) the output I expected!” On the r...   \n",
       "20  Explaining black-box classifiers using post-ho...   \n",
       "21  Algorithm runtime prediction: Methods & evalua...   \n",
       "22  Wrappers for feature subset selectionKohavi, R...   \n",
       "23  Commonsense visual sensemaking for autonomous ...   \n",
       "24  Quantum computation, quantum theory and AIYing...   \n",
       "\n",
       "                                              Authors  Published_Date  \\\n",
       "0   Silver, David, Singh, Satinder, Precup, Doina,...    October 2021   \n",
       "1           Evans, Richard, Bošnjak, Matko and 5 more    October 2021   \n",
       "2                   Prakken, Henry, Sartor, Giovanni     October 2015   \n",
       "3                                 Boden, Margaret A.      August 1998   \n",
       "4     Lemaignan, Séverin, Warnier, Mathieu and 3 more       June 2017   \n",
       "5                                        Miller, Tim    February 2019   \n",
       "6   Evans, Richard, Hernández-Orallo, José and 3 more      April 2021   \n",
       "7   Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...   February 2015   \n",
       "8   Sutton, Richard S., Precup, Doina, Singh, Sati...     August 1999   \n",
       "9         Bard, Nolan, Foerster, Jakob N. and 13 more      March 2020   \n",
       "10  van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...   February 2021   \n",
       "11               Bench-Capon, T.J.M., Dunne, Paul E.     October 2007   \n",
       "12       Bošanský, Branislav, Lisý, Viliam and 3 more     August 2016   \n",
       "13             Luo, Wenhan, Xing, Junliang and 4 more      April 2021   \n",
       "14                      Blum, Avrim L., Langley, Pat    December 1997   \n",
       "15                   Arora, Saurabh, Doshi, Prashant      August 2021   \n",
       "16      Aas, Kjersti, Jullum, Martin, Løland, Anders   September 2021   \n",
       "17  Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...       June 2021   \n",
       "18    Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.    December 2016   \n",
       "19                      Riveiro, Maria, Thill, Serge   September 2021   \n",
       "20  Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...        May 2021   \n",
       "21  Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...    January 2014   \n",
       "22                      Kohavi, Ron, John, George H.    December 1997   \n",
       "23  Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...    October 2021   \n",
       "24                                   Ying, Mingsheng    February 2010   \n",
       "\n",
       "                                            Paper_URL  \n",
       "0   https://www.sciencedirect.com/science/article/...  \n",
       "1   https://www.sciencedirect.com/science/article/...  \n",
       "2   https://www.sciencedirect.com/science/article/...  \n",
       "3   https://www.sciencedirect.com/science/article/...  \n",
       "4   https://www.sciencedirect.com/science/article/...  \n",
       "5   https://www.sciencedirect.com/science/article/...  \n",
       "6   https://www.sciencedirect.com/science/article/...  \n",
       "7   https://www.sciencedirect.com/science/article/...  \n",
       "8   https://www.sciencedirect.com/science/article/...  \n",
       "9   https://www.sciencedirect.com/science/article/...  \n",
       "10  https://www.sciencedirect.com/science/article/...  \n",
       "11  https://www.sciencedirect.com/science/article/...  \n",
       "12  https://www.sciencedirect.com/science/article/...  \n",
       "13  https://www.sciencedirect.com/science/article/...  \n",
       "14  https://www.sciencedirect.com/science/article/...  \n",
       "15  https://www.sciencedirect.com/science/article/...  \n",
       "16  https://www.sciencedirect.com/science/article/...  \n",
       "17  https://www.sciencedirect.com/science/article/...  \n",
       "18  https://www.sciencedirect.com/science/article/...  \n",
       "19  https://www.sciencedirect.com/science/article/...  \n",
       "20  https://www.sciencedirect.com/science/article/...  \n",
       "21  https://www.sciencedirect.com/science/article/...  \n",
       "22  https://www.sciencedirect.com/science/article/...  \n",
       "23  https://www.sciencedirect.com/science/article/...  \n",
       "24  https://www.sciencedirect.com/science/article/...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A python program to scrape the details of most downloaded articles from AI in last 90 days.\n",
    "#(https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\n",
    "#(Paper Title,Authors,Published Date,Paper URL)\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "page = requests.get('https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles')\n",
    "page\n",
    "soup = BeautifulSoup(page.content)\n",
    "soup\n",
    "\n",
    "titles = []\n",
    "for i in soup.find_all('li',class_='sc-9zxyh7-1 sc-9zxyh7-2 exAXfr jQmQZp'):titles.append(i.text)\n",
    "titles\n",
    "\n",
    "author = []\n",
    "for i in soup.find_all('span',class_='sc-1w3fpd7-0 pgLAT'):author.append(i.text)\n",
    "author\n",
    "\n",
    "date = []\n",
    "for i in soup.find_all('span',class_='sc-1thf9ly-2 bKddwo'):date.append(i.text)\n",
    "date\n",
    "\n",
    "page_url = []\n",
    "for i in soup.find_all('li',class_='sc-9zxyh7-1 sc-9zxyh7-2 exAXfr jQmQZp'):page_url.append(i.a['href'])\n",
    "page_url\n",
    "\n",
    "df = pd.DataFrame({'Paper_Titles':titles,'Authors':author,'Published_Date':date,'Paper_URL':page_url})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "228c0c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Publications</th>\n",
       "      <th>H5-Index</th>\n",
       "      <th>H5-Median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>Nature</td>\n",
       "      <td>414</td>\n",
       "      <td>607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>The New England Journal of Medicine</td>\n",
       "      <td>410</td>\n",
       "      <td>704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>Science</td>\n",
       "      <td>391</td>\n",
       "      <td>564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>IEEE/CVF Conference on Computer Vision and Pat...</td>\n",
       "      <td>356</td>\n",
       "      <td>583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>The Lancet</td>\n",
       "      <td>345</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96.</td>\n",
       "      <td>Frontiers in Immunology</td>\n",
       "      <td>134</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97.</td>\n",
       "      <td>Small</td>\n",
       "      <td>134</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98.</td>\n",
       "      <td>Nature Immunology</td>\n",
       "      <td>133</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99.</td>\n",
       "      <td>JAMA Oncology</td>\n",
       "      <td>133</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100.</td>\n",
       "      <td>The Lancet Neurology</td>\n",
       "      <td>133</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank                                       Publications H5-Index H5-Median\n",
       "0     1.                                             Nature      414       607\n",
       "1     2.                The New England Journal of Medicine      410       704\n",
       "2     3.                                            Science      391       564\n",
       "3     4.  IEEE/CVF Conference on Computer Vision and Pat...      356       583\n",
       "4     5.                                         The Lancet      345       600\n",
       "..   ...                                                ...      ...       ...\n",
       "95   96.                            Frontiers in Immunology      134       177\n",
       "96   97.                                              Small      134       173\n",
       "97   98.                                  Nature Immunology      133       210\n",
       "98   99.                                      JAMA Oncology      133       202\n",
       "99  100.                               The Lancet Neurology      133       200\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A python program to scrape the details of top publications from Google Scholar from\n",
    "#(https://scholar.google.com/citations?view_op=top_venues&hl=en)\n",
    "#(Rank,Publication,h5-index,h5-median)\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "page = requests.get('https://scholar.google.com/citations?view_op=top_venues&hl=en')\n",
    "page\n",
    "soup = BeautifulSoup(page.content)\n",
    "soup\n",
    "\n",
    "rank = []\n",
    "for i in soup.find_all('td',class_='gsc_mvt_p'):rank.append(i.text)\n",
    "rank\n",
    "\n",
    "publi = []\n",
    "for i in soup.find_all('td',class_='gsc_mvt_t'):publi.append(i.text)\n",
    "publi\n",
    "\n",
    "index = []\n",
    "for i in soup.find_all('a',class_='gs_ibl gsc_mp_anchor'):index.append(i.text)\n",
    "index\n",
    "\n",
    "median = []\n",
    "for i in soup.find_all('span',class_='gs_ibl gsc_mp_anchor'):median.append(i.text)\n",
    "median\n",
    "\n",
    "df = pd.DataFrame({'Rank':rank,'Publications':publi,'H5-Index':index,'H5-Median':median})\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cded62a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
